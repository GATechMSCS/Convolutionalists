{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae27b52a-395a-4cf1-b771-2b46271ec61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.models import vit_b_16, vit_l_16\n",
    "from torchvision.models import ViT_B_16_Weights\n",
    "from src.model_managers.standard_model_manager import StandardModelManager\n",
    "\n",
    "from src.dataset_loaders.download_openimages import OpenImagesLoader\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "\n",
    "from transformers import AutoImageProcessor, DetrForObjectDetection\n",
    "from PIL import Image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af7f95ad-cf5c-4ded-a359-ac932338764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device Configuration:\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Device being used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0b78a-58d9-4169-99bd-3539ece25ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 64\n",
      "Splitting data for class Hot dog\n",
      "Splitting data for class French fries\n",
      "Splitting data for class Waffle\n",
      "Splitting data for class Pancake\n",
      "Splitting data for class Burrito\n",
      "Splitting data for class Pretzel\n",
      "Splitting data for class Popcorn\n",
      "Splitting data for class Cookie\n",
      "Splitting data for class Muffin\n",
      "Splitting data for class Ice cream\n",
      "Splitting data for class Cake\n",
      "Splitting data for class Candy\n",
      "Splitting data for class Guacamole\n",
      "Splitting data for class Apple\n",
      "Splitting data for class Grape\n",
      "Splitting data for class Common fig\n",
      "Splitting data for class Pear\n",
      "Splitting data for class Strawberry\n",
      "Splitting data for class Tomato\n",
      "Splitting data for class Lemon\n",
      "Splitting data for class Banana\n",
      "Splitting data for class Orange\n",
      "Splitting data for class Peach\n",
      "Splitting data for class Mango\n",
      "Splitting data for class Pineapple\n",
      "Splitting data for class Grapefruit\n",
      "Splitting data for class Pomegranate\n",
      "Splitting data for class Watermelon\n",
      "Splitting data for class Cantaloupe\n",
      "Splitting data for class Egg (Food)\n",
      "Splitting data for class Bagel\n",
      "Splitting data for class Bread\n",
      "Splitting data for class Doughnut\n",
      "Splitting data for class Croissant\n",
      "Splitting data for class Tart\n",
      "Splitting data for class Mushroom\n",
      "Splitting data for class Pasta\n",
      "Splitting data for class Pizza\n",
      "Splitting data for class Squid\n",
      "Splitting data for class Oyster\n",
      "Splitting data for class Lobster\n",
      "Splitting data for class Shrimp\n",
      "Splitting data for class Crab\n",
      "Splitting data for class Taco\n",
      "Splitting data for class Cooking spray\n",
      "Splitting data for class Cucumber\n",
      "Splitting data for class Radish\n",
      "Splitting data for class Artichoke\n",
      "Splitting data for class Potato\n",
      "Splitting data for class Garden Asparagus\n",
      "Splitting data for class Pumpkin\n",
      "Splitting data for class Zucchini\n",
      "Splitting data for class Cabbage\n",
      "Splitting data for class Carrot\n",
      "Splitting data for class Salad\n",
      "Splitting data for class Broccoli\n",
      "Splitting data for class Bell pepper\n",
      "Splitting data for class Winter melon\n",
      "Splitting data for class Honeycomb\n",
      "Splitting data for class Hamburger\n",
      "Splitting data for class Submarine sandwich\n",
      "Splitting data for class Cheese\n",
      "Splitting data for class Milk\n",
      "Splitting data for class Sushi\n",
      "Dataset has been reduced!\n"
     ]
    }
   ],
   "source": [
    "### Loading Open Images Dataset:\n",
    "\n",
    "\n",
    "# Data Configuration & Hyperparameters:\n",
    "PERC_KEEP = 0.10 # Proportion of data from datasets to keep\n",
    "BATCH_SIZE = 16 # Batch size\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 5e-4\n",
    "\n",
    "oi_loader = OpenImagesLoader(batch_size=BATCH_SIZE, perc_keep=PERC_KEEP)\n",
    "print(f\"Number of classes: {len(oi_loader.classes)}\")\n",
    "\n",
    "# Loading the Open Images Dataset:\n",
    "# oi_loader.download_data()\n",
    "# oi_loader.split_data(keep_class_dirs=False)\n",
    "# oi_loader.split_data_reduced(keep_class_dirs=False)\n",
    "train_set, val_set, test_set = oi_loader.get_dataloaders()\n",
    "\n",
    "print(f\"Number of Batches in Training Set: {len(train_set)}\")\n",
    "print(f\"Number of Batches in Validation Set: {len(val_set)}\")\n",
    "print(f\"Number of Batches in Testing Set: {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36942380-5c19-4213-8d50-d40dec1a1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading DETR Resnet-50 Model from HuggingFace:\n",
    "\n",
    "img_proc = AutoImageProcessor.from_pretrained('facebook/detr-resnet-50')\n",
    "detr_model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "inputs = img_proc(\n",
    "outputs = detr_model(**inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09639780-9a4f-429d-932b-f6902b034764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd3bc0-7e74-4308-85dc-6fda4e356d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4621314-096d-455c-af58-f6397537718c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9084c28-fc88-4b7f-8a53-9af341b046a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24319b6-feb1-4744-85b7-4be33979e1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9323d22-4e15-45a9-86e5-248623f62f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading vit_b_16 model with pre-trained weights on the ImageNet dataset:\n",
    "vit_b = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Number of classes of the Fruit360 dataset:\n",
    "num_classes = 141\n",
    "\n",
    "# Adjusting the last layer of the transformer to perform classification on the Fruits360 dataset:\n",
    "vit_b.heads.head = nn.Linear(in_features=768, out_features=num_classes)\n",
    "\n",
    "# Freezing the architecture:\n",
    "for param in vit_b.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreezing the architecture in the last layer to fine-tune model:\n",
    "for param in vit_b.heads.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model Training Configuration:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(vit_b.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Wrapping the model in the StandardModelManager:\n",
    "vit_b_wrapper = StandardModelManager(model=vit_b, criterion=criterion, optimizer=optimizer, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3ecdb-a7f6-4385-acbb-b1c76e8ca8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model:\n",
    "vit_b_wrapper.train(training_data_loader=train_360, validation_data_loader=val_360, epochs=EPOCHS)\n",
    "\n",
    "# Creating, saving, and displaying learning curve from training:\n",
    "vit_b_wrapper.plot_learning_curve(\"vit_b_16\")\n",
    "\n",
    "# Testing the model:\n",
    "vit_b_wrapper.test(test_360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d8705-c919-4e09-9b92-8e73933fce32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convolutionalists",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
