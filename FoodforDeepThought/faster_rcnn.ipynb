{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cpu\n"
     ]
    }
   ],
   "source": [
    "# utils\n",
    "from src.model_managers.standard_model_manager import (StandardModelManager,\n",
    "                                                       FRCNNModelManager)\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# torch\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import (fasterrcnn_resnet50_fpn_v2, \n",
    "                                         fasterrcnn_resnet50_fpn)\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "#import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "# transfomers\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# load data\n",
    "from src.dataset_loaders.download_openimages import (OpenImagesLoader,\n",
    "                                                     ImageLoaderFRCNN)\n",
    "from src.dataset_loaders.fruits360 import Fruits360Loader\n",
    "\n",
    "# set device\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "\n",
    "print(f\"Device being used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12531, 1601, 1660)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "# fl = Fruits360Loader(random_seed=101,\n",
    "#                      batch_size=128,\n",
    "#                      perc_keep=1.0)\n",
    "# train_fl, val_fl, test_fl = fl.load_data()\n",
    "\n",
    "# oil = OpenImagesLoader(random_seed=101,\n",
    "#                        batch_size=128,\n",
    "#                        perc_keep=1.0,\n",
    "#                        num_images_per_class=500,)\n",
    "\n",
    "# oil.download_data(annotation_format='pascal')\n",
    "# oil.split_data(keep_class_dirs=False)\n",
    "#train, val, test = oil.get_datasets()\n",
    "\n",
    "\n",
    "# csb = pd.read_csv(\"data/openimages_csv_dir/class-descriptions-boxable.csv\",\n",
    "#                   header=None,\n",
    "#                   names=['LabelName',\n",
    "#                            'Label'])\n",
    "# trabb = pd.read_csv(\"data/openimages_csv_dir/train-annotations-bbox.csv\",)\n",
    "# vabb = pd.read_csv(\"data/openimages_csv_dir/validation-annotations-bbox.csv\",)\n",
    "# teabb = pd.read_csv(\"data/openimages_csv_dir/test-annotations-bbox.csv\",)\n",
    "\n",
    "# food_cats = [\"Hot dog\", \"French fries\", \"Waffle\", \"Pancake\", \"Burrito\", \"Pretzel\",\n",
    "#             \"Popcorn\", \"Cookie\", \"Muffin\", \"Ice cream\", \"Cake\", \"Candy\",\n",
    "#             \"Guacamole\", \"Apple\", \"Grape\", \"Common fig\", \"Pear\",\n",
    "#             \"Strawberry\", \"Tomato\", \"Lemon\", \"Banana\", \"Orange\", \"Peach\", \"Mango\",\n",
    "#             \"Pineapple\", \"Grapefruit\", \"Pomegranate\", \"Watermelon\", \"Cantaloupe\",\n",
    "#             \"Egg (Food)\", \"Bagel\", \"Bread\", \"Doughnut\", \"Croissant\",\n",
    "#             \"Tart\", \"Mushroom\", \"Pasta\", \"Pizza\", \"Squid\",\n",
    "#             \"Oyster\", \"Lobster\", \"Shrimp\", \"Crab\", \"Taco\", \"Cooking spray\",\n",
    "#             \"Cucumber\", \"Radish\", \"Artichoke\", \"Potato\", \"Garden Asparagus\",\n",
    "#             \"Pumpkin\", \"Zucchini\", \"Cabbage\", \"Carrot\", \"Salad\",\n",
    "#             \"Broccoli\", \"Bell pepper\", \"Winter melon\", \"Honeycomb\",\n",
    "#             \"Hamburger\", \"Submarine sandwich\", \"Cheese\", \"Milk\", \"Sushi\"]\n",
    "\n",
    "# csb = csb[csb['Label'].isin(food_cats)]\n",
    "# csb\n",
    "\n",
    "# print(len(trabb))\n",
    "# trabb = trabb[trabb['LabelName'].isin(csb[\"LabelName\"])]\n",
    "# print(len(trabb))\n",
    "# trabb_csb = pd.merge(csb, trabb, on='LabelName', how='inner')\n",
    "# print(len(trabb_csb))\n",
    "# trabb_csb\n",
    "\n",
    "# print(len(vabb))\n",
    "# vabb = vabb[vabb['LabelName'].isin(csb[\"LabelName\"])]\n",
    "# print(len(vabb))\n",
    "# vabb_csb = pd.merge(csb, vabb, on='LabelName', how='inner')\n",
    "# print(len(vabb_csb))\n",
    "# vabb_csb\n",
    "\n",
    "# print(len(teabb))\n",
    "# teabb = teabb[teabb['LabelName'].isin(csb[\"LabelName\"])]\n",
    "# print(len(teabb))\n",
    "# teabb_csb = pd.merge(csb, teabb, on='LabelName', how='inner')\n",
    "# print(len(teabb_csb))\n",
    "# teabb_csb\n",
    "\n",
    "# train_target = [{\"label\": torch.Tensor(row[\"Label\"]),\n",
    "#                  \"boxes\": torch.tensor([row[\"XMin\"], row[\"XMax\"], row[\"YMin\"], row[\"YMax\"]])}\n",
    "#                 for _, row in trabb_csb.iterrows()]\n",
    "# train_target\n",
    "\n",
    "def get_transform(train):\n",
    "    transf = []\n",
    "    transf.append(v2.ToTensor())\n",
    "    if train:\n",
    "        transf.append(v2.Normalize(mean=[0.485,\n",
    "                                                 0.456,\n",
    "                                                 0.406],\n",
    "                                           std=[0.229,\n",
    "                                                0.224,\n",
    "                                                0.225]))\n",
    "\n",
    "    return v2.Compose(transf)\n",
    "\n",
    "ttform = get_transform(train=True)\n",
    "vtform = get_transform(train=False)\n",
    "    \n",
    "loader = OpenImagesLoader()\n",
    "opim_dir = loader.data_dir\n",
    "seed = loader.random_seed\n",
    "batch_size = loader.batch_size\n",
    "per_keep = loader.perc_keep\n",
    "im_per_class = loader.num_images_per_class\n",
    "\n",
    "ann_form = loader.annotation_format\n",
    "classes = loader.classes\n",
    "class2index = loader.class_2_index\n",
    "train_direct = loader.train_dir\n",
    "val_direct = loader.val_dir\n",
    "test_direct = loader.test_dir\n",
    "\n",
    "train_dataset = ImageLoaderFRCNN(root=train_direct,\n",
    "                                 classes=classes,\n",
    "                                 tforms=ttform)\n",
    "val_dataset = ImageLoaderFRCNN(root=val_direct,\n",
    "                               classes=classes,\n",
    "                               tforms=vtform)\n",
    "test_dataset = ImageLoaderFRCNN(root=test_direct,\n",
    "                               classes=classes,)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 8, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx = list(range(7500))  # This will include indices 0 to 7500\n",
    "val_idx = list(range(1000))  # This will include indices 0 to 1000\n",
    "test_idx = list(range(1000))  # This will include indices 0 to 1000\n",
    "tr_samp = SubsetRandomSampler(train_idx)\n",
    "val_samp = SubsetRandomSampler(val_idx)\n",
    "te_samp = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# without sampling lengths were train_loader: 98, val_loader: 13, test_loader: 13\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=lambda x: tuple(zip(*x)),\n",
    "                                           sampler=tr_samp)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=lambda x: tuple(zip(*x)),\n",
    "                                         sampler=val_samp)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=lambda x: tuple(zip(*x)),\n",
    "                                         sampler=te_samp)\n",
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get/create model\n",
    "def get_model(num_classes):\n",
    "    # model types: fasterrcnn_resnet50_fpn,\n",
    "    #              fasterrcnn_resnet50_fpn_v2,\n",
    "    #              fasterrcnn_mobilenet_v3_large_fpn,\n",
    "    #              fasterrcnn_mobilenet_v3_large_320_fpn\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "        \n",
    "model = get_model(num_classes=138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate model\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "metric = MeanAveragePrecision()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "smmfr = FRCNNModelManager(model=model, \n",
    "                         metric=metric, \n",
    "                         optimizer=optimizer,\n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/leonardo_leads/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/leonardo_leads/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/leonardo_leads/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/leonardo_leads/Documents/SchoolDocs/ga_tech_masters/omscs_ml/Convolutionalists/FoodforDeepThought/src/dataset_loaders/download_openimages.py\", line 469, in __getitem__\n    labels.append(self.classes.index(label))\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: 'Egg (food)' is not in list\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fruits 360\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# smm.train(training_data_loader=train_fl,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#           validation_data_loader=val,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#           epochs=epochs,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#           has_box=False)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43msmmfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhas_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SchoolDocs/ga_tech_masters/omscs_ml/Convolutionalists/FoodforDeepThought/src/model_managers/standard_model_manager.py:207\u001b[0m, in \u001b[0;36mFRCNNModelManager.train\u001b[0;34m(self, training_data_loader, validation_data_loader, epochs, has_box)\u001b[0m\n\u001b[1;32m    205\u001b[0m display_epoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    206\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 207\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraining_data_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1465\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/_utils.py:715\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/leonardo_leads/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/leonardo_leads/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/leonardo_leads/miniconda3/envs/convolutionalists/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/leonardo_leads/Documents/SchoolDocs/ga_tech_masters/omscs_ml/Convolutionalists/FoodforDeepThought/src/dataset_loaders/download_openimages.py\", line 469, in __getitem__\n    labels.append(self.classes.index(label))\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: 'Egg (food)' is not in list\n"
     ]
    }
   ],
   "source": [
    "# fruits 360\n",
    "# smm.train(training_data_loader=train_fl,\n",
    "#           validation_data_loader=val,\n",
    "#           epochs=epochs,\n",
    "#           has_box=False)\n",
    "\n",
    "smmfr.train(training_data_loader=train_loader,\n",
    "            validation_data_loader=val_loader,\n",
    "            epochs=epochs,\n",
    "            has_box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convolutionalists",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
