{"cells":[{"cell_type":"code","source":["# Mount into drive\n","\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","\n","%cd '/content/drive/MyDrive/ColabNotebooks/gt_omscs_ml/deep_learning/Convolutionalists/FoodforDeepThought'\n","\n","!pip install -q condacolab\n","import condacolab\n","condacolab.install()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"OLE73T11EpzF","executionInfo":{"status":"ok","timestamp":1733852555991,"user_tz":360,"elapsed":3678,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"outputId":"3e744b7c-ce06-4a20-8d0f-09239d94db6f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/ColabNotebooks/gt_omscs_ml/deep_learning/Convolutionalists/FoodforDeepThought\n","âœ¨ðŸ°âœ¨ Everything looks OK!\n"]}]},{"cell_type":"code","source":["!conda install pip pytorch=2.5.1 torchvision=0.20.1 jupyter ipykernel torchmetrics"],"metadata":{"collapsed":true,"id":"WNpfiZpWU9cJ","executionInfo":{"status":"ok","timestamp":1733852642303,"user_tz":360,"elapsed":86314,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5be1deee-5782-4854-fff4-eb69501f5fa6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Channels:\n"," - conda-forge\n","Platform: linux-64\n","Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n","Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n","\n","\n","==> WARNING: A newer version of conda exists. <==\n","    current version: 23.11.0\n","    latest version: 24.11.0\n","\n","Please update conda by running\n","\n","    $ conda update -n base -c conda-forge conda\n","\n","\n","\n","# All requested packages already installed.\n","\n"]}]},{"cell_type":"code","source":["!pip install openimages ultralytics==8.3.40 opencv-python matplotlib Pillow requests scipy tqdm pandas seaborn tensorboard torchmetrics[detection] transformers==4.46.3"],"metadata":{"collapsed":true,"id":"Iqo-K4bMVI6N","executionInfo":{"status":"ok","timestamp":1733852645278,"user_tz":360,"elapsed":2980,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"62004489-8909-4195-8c82-29b2cc6f0bbb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openimages in /usr/local/lib/python3.10/site-packages (0.0.1)\n","Requirement already satisfied: ultralytics==8.3.40 in /usr/local/lib/python3.10/site-packages (8.3.40)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/site-packages (4.10.0.84)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.9.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (11.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (2.31.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (1.14.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (4.66.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (2.2.3)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/site-packages (0.13.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/site-packages (2.18.0)\n","Requirement already satisfied: transformers==4.46.3 in /usr/local/lib/python3.10/site-packages (4.46.3)\n","Requirement already satisfied: torchmetrics[detection] in /usr/local/lib/python3.10/site-packages (1.5.2)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (2.2.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (6.0.2)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (2.5.1.post306)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (0.20.1a0+9f8010e)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (6.1.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (9.0.0)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (2.0.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (0.26.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (23.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (0.4.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/site-packages (from openimages) (1.35.77)\n","Requirement already satisfied: cvdata in /usr/local/lib/python3.10/site-packages (from openimages) (0.0.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/site-packages (from openimages) (5.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.55.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests) (2024.8.30)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas) (2024.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/site-packages (from tensorboard) (1.68.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/site-packages (from tensorboard) (5.29.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/site-packages (from tensorboard) (68.2.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/site-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/site-packages (from torchmetrics[detection]) (0.11.9)\n","Requirement already satisfied: pycocotools>2.0.0 in /usr/local/lib/python3.10/site-packages (from torchmetrics[detection]) (2.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (4.12.2)\n","Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.3.40) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.3.40) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.3.40) (3.1.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","Requirement already satisfied: botocore<1.36.0,>=1.35.77 in /usr/local/lib/python3.10/site-packages (from boto3->openimages) (1.35.77)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/site-packages (from boto3->openimages) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/site-packages (from boto3->openimages) (0.10.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.8.0->ultralytics==8.3.40) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aEL9vgidEmIV","executionInfo":{"status":"ok","timestamp":1733856742536,"user_tz":360,"elapsed":272,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"outputId":"6048dff4-5f27-4d61-d4ad-7b758a09dff8","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Device being used: cuda\n"]}],"source":["# utils\n","from src.model_managers.standard_model_manager import (StandardModelManager,\n","                                                       FRCNNModelManager)\n","from tqdm import tqdm, tqdm_notebook\n","import matplotlib as plt\n","import pandas as pd\n","import numpy as np\n","import time\n","import os\n","\n","# torch\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import (fasterrcnn_resnet50_fpn_v2,\n","                                         fasterrcnn_resnet50_fpn)\n","from torchmetrics.detection.mean_ap import MeanAveragePrecision\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms\n","from torchvision.transforms import v2\n","from torchvision import tv_tensors\n","import torch.optim as optim\n","import torch.nn as nn\n","import torchvision\n","import torch\n","\n","# transfomers\n","from transformers import BertTokenizer, BertForQuestionAnswering\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# load data\n","from src.dataset_loaders.download_openimages import (OpenImagesLoader,\n","                                                     ImageLoaderFRCNN)\n","from src.dataset_loaders.fruits360 import Fruits360Loader\n","\n","# set device\n","device = 'cpu'\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","elif torch.backends.mps.is_available():\n","    device = 'mps'\n","\n","print(f\"Device being used: {device}\")"]},{"cell_type":"code","execution_count":35,"metadata":{"collapsed":true,"id":"hHVMjbILEmId","executionInfo":{"status":"ok","timestamp":1733856745630,"user_tz":360,"elapsed":984,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6393551-3fc6-4c4e-fb66-c5b49c74368d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12418, 1584, 1647)"]},"metadata":{},"execution_count":35}],"source":["def get_transform(train):\n","    transf = []\n","    #transf.append(v2.Resize((100)))\n","    transf.append(v2.ToTensor())\n","    if train:\n","        transf.append(v2.Normalize(mean=[0.485,\n","                                         0.456,\n","                                         0.406],\n","                                   std=[0.229,\n","                                        0.224,\n","                                        0.225]))\n","\n","    return v2.Compose(transf)\n","\n","ttform = get_transform(train=True)\n","vtform = get_transform(train=False)\n","\n","loader = OpenImagesLoader(random_seed=101,\n","                         batch_size=2,\n","                         perc_keep=1.0,\n","                         num_images_per_class=500,)\n","opim_dir = loader.data_dir\n","seed = loader.random_seed\n","batch_size = loader.batch_size\n","per_keep = loader.perc_keep\n","im_per_class = loader.num_images_per_class\n","\n","ann_form = loader.annotation_format\n","classes = loader.classes\n","class2index = loader.class_2_index\n","train_direct = loader.train_dir\n","val_direct = loader.val_dir\n","test_direct = loader.test_dir\n","\n","train_dataset = ImageLoaderFRCNN(root=train_direct,\n","                                 classes=classes,\n","                                 tforms=ttform)\n","val_dataset = ImageLoaderFRCNN(root=val_direct,\n","                               classes=classes,\n","                               tforms=vtform)\n","test_dataset = ImageLoaderFRCNN(root=test_direct,\n","                               classes=classes,)\n","\n","len(train_dataset), len(val_dataset), len(test_dataset)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"p2k3Nc-qEmIe","executionInfo":{"status":"ok","timestamp":1733856745630,"user_tz":360,"elapsed":4,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cba08b37-e5a8-445d-dacf-b6929dc5cc77"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6209, 792, 824)"]},"metadata":{},"execution_count":36}],"source":["train_idx = list(range(6209))  # This will include indices 0 to 2500\n","val_idx = list(range(1000))  # This will include indices 0 to 1000\n","test_idx = list(range(1000))  # This will include indices 0 to 1000\n","tr_samp = SubsetRandomSampler(train_idx)\n","val_samp = SubsetRandomSampler(val_idx)\n","te_samp = SubsetRandomSampler(test_idx)\n","\n","def collate(data):\n","    return tuple(zip(*data))\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=False,\n","                                           num_workers=4,\n","                                           collate_fn=collate,)\n","                                           #sampler=tr_samp)\n","val_loader = torch.utils.data.DataLoader(val_dataset,\n","                                         batch_size=batch_size,\n","                                         shuffle=False,\n","                                         num_workers=4,\n","                                         collate_fn=collate,)\n","                                         #sampler=val_samp)\n","test_loader = torch.utils.data.DataLoader(test_dataset,\n","                                         batch_size=batch_size,\n","                                         shuffle=False,\n","                                         num_workers=4,\n","                                         collate_fn=collate,)\n","                                         #sampler=te_samp)\n","len(train_loader), len(val_loader), len(test_loader)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"do8QGVOJEmIf","executionInfo":{"status":"ok","timestamp":1733856746861,"user_tz":360,"elapsed":1234,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}}},"outputs":[],"source":["# create model\n","def get_model(num_classes):\n","    model = fasterrcnn_resnet50_fpn_v2(weights=\"COCO_V1\")\n","\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","    return model\n","\n","model = get_model(num_classes=138)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"AWGOjtEZEmIg","executionInfo":{"status":"ok","timestamp":1733856746861,"user_tz":360,"elapsed":3,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}}},"outputs":[],"source":["# train and evaluate model\n","lr = 0.001\n","epochs = 10\n","metric = MeanAveragePrecision()\n","optimizer = optim.AdamW(model.parameters(), lr=lr)\n","smmfr = FRCNNModelManager(model=model,\n","                         metric=metric,\n","                         optimizer=optimizer,\n","                         device=device)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"r6DhEiYbEmIh","executionInfo":{"status":"error","timestamp":1733858309083,"user_tz":360,"elapsed":1561552,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":671},"outputId":"cd51ea82-b01b-467c-989e-d11b6b88e21c"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x78b7b4542170>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1568, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n","    res = self._popen.wait(timeout)\n","  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n","    if not wait([self.sentinel], timeout):\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt: \n","  0%|          | 0/10 [26:01<?, ?it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-f70843126764>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m smmfr.train(training_data_loader=train_loader,\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mvalidation_data_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             epochs=epochs,)\n","\u001b[0;32m/content/drive/MyDrive/ColabNotebooks/gt_omscs_ml/deep_learning/Convolutionalists/FoodforDeepThought/src/model_managers/standard_model_manager.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data_loader, validation_data_loader, epochs)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# note that we detach the deltas because Faster R-CNN do not backprop through\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# the proposals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mproposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_coder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_bbox_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0mproposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_proposals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjectness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_anchors_per_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/torchvision/models/detection/_utils.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbox_sum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mrel_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbox_sum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/torchvision/models/detection/_utils.py\u001b[0m in \u001b[0;36mdecode_single\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Distance from center to box's corner.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mc_to_c_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_ctr_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpred_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mc_to_c_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_ctr_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpred_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["smmfr.train(training_data_loader=train_loader,\n","            validation_data_loader=val_loader,\n","            epochs=epochs,)"]},{"cell_type":"code","source":[],"metadata":{"id":"xJ2D0c9OsfHw"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}