{"cells":[{"cell_type":"code","source":["# Mount into drive\n","\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","\n","%cd '/content/drive/MyDrive/ColabNotebooks/gt_omscs_ml/deep_learning/Convolutionalists/FoodforDeepThought'\n","\n","!pip install -q condacolab\n","import condacolab\n","condacolab.install()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"OLE73T11EpzF","executionInfo":{"status":"ok","timestamp":1733807039699,"user_tz":360,"elapsed":4583,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"outputId":"dafe1b04-77e5-4d90-a595-882dba4ef040"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/ColabNotebooks/gt_omscs_ml/deep_learning/Convolutionalists/FoodforDeepThought\n","âœ¨ðŸ°âœ¨ Everything looks OK!\n"]}]},{"cell_type":"code","source":["!conda install pip pytorch=2.5.1 torchvision=0.20.1 jupyter ipykernel torchmetrics"],"metadata":{"collapsed":true,"id":"WNpfiZpWU9cJ","executionInfo":{"status":"ok","timestamp":1733807110979,"user_tz":360,"elapsed":71287,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d65f17f8-ec3b-45a0-c120-ce2c0b222796"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Channels:\n"," - conda-forge\n","Platform: linux-64\n","Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n","Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","\n","\n","==> WARNING: A newer version of conda exists. <==\n","    current version: 23.11.0\n","    latest version: 24.11.0\n","\n","Please update conda by running\n","\n","    $ conda update -n base -c conda-forge conda\n","\n","\n","\n","# All requested packages already installed.\n","\n"]}]},{"cell_type":"code","source":["!pip install openimages ultralytics==8.3.40 opencv-python matplotlib Pillow requests scipy tqdm pandas seaborn tensorboard torchmetrics[detection] transformers==4.46.3"],"metadata":{"collapsed":true,"id":"Iqo-K4bMVI6N","executionInfo":{"status":"ok","timestamp":1733807113702,"user_tz":360,"elapsed":2729,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cc6f3d89-ce23-4902-c026-bb10fa7c2d43"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openimages in /usr/local/lib/python3.10/site-packages (0.0.1)\n","Requirement already satisfied: ultralytics==8.3.40 in /usr/local/lib/python3.10/site-packages (8.3.40)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/site-packages (4.10.0.84)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.9.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (11.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (2.31.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (1.14.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (4.66.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (2.2.3)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/site-packages (0.13.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/site-packages (2.18.0)\n","Requirement already satisfied: transformers==4.46.3 in /usr/local/lib/python3.10/site-packages (4.46.3)\n","Requirement already satisfied: torchmetrics[detection] in /usr/local/lib/python3.10/site-packages (1.5.2)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (2.2.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (6.0.2)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (2.5.1.post306)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (0.20.1a0+9f8010e)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (6.1.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (9.0.0)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/site-packages (from ultralytics==8.3.40) (2.0.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (0.26.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (23.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.46.3) (0.4.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/site-packages (from openimages) (1.35.77)\n","Requirement already satisfied: cvdata in /usr/local/lib/python3.10/site-packages (from openimages) (0.0.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/site-packages (from openimages) (5.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.55.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests) (2024.8.30)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas) (2024.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/site-packages (from tensorboard) (1.68.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/site-packages (from tensorboard) (5.29.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/site-packages (from tensorboard) (68.2.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/site-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/site-packages (from torchmetrics[detection]) (0.11.9)\n","Requirement already satisfied: pycocotools>2.0.0 in /usr/local/lib/python3.10/site-packages (from torchmetrics[detection]) (2.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (4.12.2)\n","Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.3.40) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.3.40) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.3.40) (3.1.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","Requirement already satisfied: botocore<1.36.0,>=1.35.77 in /usr/local/lib/python3.10/site-packages (from boto3->openimages) (1.35.77)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/site-packages (from boto3->openimages) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/site-packages (from boto3->openimages) (0.10.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.8.0->ultralytics==8.3.40) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aEL9vgidEmIV","executionInfo":{"status":"ok","timestamp":1733807129403,"user_tz":360,"elapsed":15705,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"outputId":"0c6b641c-e584-4594-8328-345cfaf01438"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device being used: cuda\n"]}],"source":["# utils\n","from src.model_managers.standard_model_manager import (StandardModelManager,\n","                                                       FRCNNModelManager)\n","from tqdm import tqdm, tqdm_notebook\n","import matplotlib as plt\n","import pandas as pd\n","import numpy as np\n","import time\n","import os\n","\n","# torch\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import (fasterrcnn_resnet50_fpn_v2,\n","                                         fasterrcnn_resnet50_fpn)\n","from torchmetrics.detection.mean_ap import MeanAveragePrecision\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms\n","from torchvision.transforms import v2\n","from torchvision import tv_tensors\n","import torch.optim as optim\n","import torch.nn as nn\n","import torchvision\n","import torch\n","\n","# transfomers\n","from transformers import BertTokenizer, BertForQuestionAnswering\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# load data\n","from src.dataset_loaders.download_openimages import (OpenImagesLoader,\n","                                                     ImageLoaderFRCNN)\n","from src.dataset_loaders.fruits360 import Fruits360Loader\n","\n","# set device\n","device = 'cpu'\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","elif torch.backends.mps.is_available():\n","    device = 'mps'\n","\n","print(f\"Device being used: {device}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"id":"hHVMjbILEmId","executionInfo":{"status":"ok","timestamp":1733807129987,"user_tz":360,"elapsed":589,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b311f154-965e-4a71-a98d-69ca027f9632"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12418, 1584, 1647)"]},"metadata":{},"execution_count":5}],"source":["# get data\n","# fl = Fruits360Loader(random_seed=101,\n","#                      batch_size=128,\n","#                      perc_keep=1.0)\n","# train_fl, val_fl, test_fl = fl.load_data()\n","\n","# oil = OpenImagesLoader(random_seed=101,\n","#                         batch_size=128,\n","#                         perc_keep=1.0,\n","#                         num_images_per_class=500,\n","#                        annotation_format='pascal')\n","\n","# oil.download_data()\n","# oil.split_data(keep_class_dirs=False)\n","#train, val, test = oil.get_datasets()\n","\n","\n","# csb = pd.read_csv(\"data/openimages_csv_dir/class-descriptions-boxable.csv\",\n","#                   header=None,\n","#                   names=['LabelName',\n","#                            'Label'])\n","# trabb = pd.read_csv(\"data/openimages_csv_dir/train-annotations-bbox.csv\",)\n","# vabb = pd.read_csv(\"data/openimages_csv_dir/validation-annotations-bbox.csv\",)\n","# teabb = pd.read_csv(\"data/openimages_csv_dir/test-annotations-bbox.csv\",)\n","\n","# food_cats = [\"Hot dog\", \"French fries\", \"Waffle\", \"Pancake\", \"Burrito\", \"Pretzel\",\n","#             \"Popcorn\", \"Cookie\", \"Muffin\", \"Ice cream\", \"Cake\", \"Candy\",\n","#             \"Guacamole\", \"Apple\", \"Grape\", \"Common fig\", \"Pear\",\n","#             \"Strawberry\", \"Tomato\", \"Lemon\", \"Banana\", \"Orange\", \"Peach\", \"Mango\",\n","#             \"Pineapple\", \"Grapefruit\", \"Pomegranate\", \"Watermelon\", \"Cantaloupe\",\n","#             \"Egg (Food)\", \"Bagel\", \"Bread\", \"Doughnut\", \"Croissant\",\n","#             \"Tart\", \"Mushroom\", \"Pasta\", \"Pizza\", \"Squid\",\n","#             \"Oyster\", \"Lobster\", \"Shrimp\", \"Crab\", \"Taco\", \"Cooking spray\",\n","#             \"Cucumber\", \"Radish\", \"Artichoke\", \"Potato\", \"Garden Asparagus\",\n","#             \"Pumpkin\", \"Zucchini\", \"Cabbage\", \"Carrot\", \"Salad\",\n","#             \"Broccoli\", \"Bell pepper\", \"Winter melon\", \"Honeycomb\",\n","#             \"Hamburger\", \"Submarine sandwich\", \"Cheese\", \"Milk\", \"Sushi\"]\n","\n","# csb = csb[csb['Label'].isin(food_cats)]\n","# csb\n","\n","# print(len(trabb))\n","# trabb = trabb[trabb['LabelName'].isin(csb[\"LabelName\"])]\n","# print(len(trabb))\n","# trabb_csb = pd.merge(csb, trabb, on='LabelName', how='inner')\n","# print(len(trabb_csb))\n","# trabb_csb\n","\n","# print(len(vabb))\n","# vabb = vabb[vabb['LabelName'].isin(csb[\"LabelName\"])]\n","# print(len(vabb))\n","# vabb_csb = pd.merge(csb, vabb, on='LabelName', how='inner')\n","# print(len(vabb_csb))\n","# vabb_csb\n","\n","# print(len(teabb))\n","# teabb = teabb[teabb['LabelName'].isin(csb[\"LabelName\"])]\n","# print(len(teabb))\n","# teabb_csb = pd.merge(csb, teabb, on='LabelName', how='inner')\n","# print(len(teabb_csb))\n","# teabb_csb\n","\n","# train_target = [{\"label\": torch.Tensor(row[\"Label\"]),\n","#                  \"boxes\": torch.tensor([row[\"XMin\"], row[\"XMax\"], row[\"YMin\"], row[\"YMax\"]])}\n","#                 for _, row in trabb_csb.iterrows()]\n","# train_target\n","\n","def get_transform(train):\n","    transf = []\n","    transf.append(v2.Resize((100)))\n","    transf.append(v2.ToTensor())\n","    if train:\n","        transf.append(v2.Normalize(mean=[0.485,\n","                                         0.456,\n","                                         0.406],\n","                                   std=[0.229,\n","                                        0.224,\n","                                        0.225]))\n","\n","    return v2.Compose(transf)\n","\n","ttform = get_transform(train=True)\n","vtform = get_transform(train=False)\n","\n","loader = OpenImagesLoader(random_seed=101,\n","                         batch_size=2,\n","                         perc_keep=1.0,\n","                         num_images_per_class=500,)\n","opim_dir = loader.data_dir\n","seed = loader.random_seed\n","batch_size = loader.batch_size\n","per_keep = loader.perc_keep\n","im_per_class = loader.num_images_per_class\n","\n","ann_form = loader.annotation_format\n","classes = loader.classes\n","class2index = loader.class_2_index\n","train_direct = loader.train_dir\n","val_direct = loader.val_dir\n","test_direct = loader.test_dir\n","\n","train_dataset = ImageLoaderFRCNN(root=train_direct,\n","                                 classes=classes,\n","                                 tforms=ttform)\n","val_dataset = ImageLoaderFRCNN(root=val_direct,\n","                               classes=classes,\n","                               tforms=vtform)\n","test_dataset = ImageLoaderFRCNN(root=test_direct,\n","                               classes=classes,)\n","\n","len(train_dataset), len(val_dataset), len(test_dataset)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"p2k3Nc-qEmIe","executionInfo":{"status":"ok","timestamp":1733807129987,"user_tz":360,"elapsed":4,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b8ec14c-0ba0-4596-9ff5-60cb652771cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 50, 50)"]},"metadata":{},"execution_count":6}],"source":["train_idx = list(range(1000))  # This will include indices 0 to 7500\n","val_idx = list(range(100))  # This will include indices 0 to 1000\n","test_idx = list(range(100))  # This will include indices 0 to 1000\n","tr_samp = SubsetRandomSampler(train_idx)\n","val_samp = SubsetRandomSampler(val_idx)\n","te_samp = SubsetRandomSampler(test_idx)\n","\n","def collate(data):\n","    return tuple(zip(*data))\n","\n","# without sampling lengths were train_loader: 98, val_loader: 13, test_loader: 13\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=False,\n","                                           num_workers=4,\n","                                           collate_fn=collate,\n","                                           sampler=tr_samp)\n","val_loader = torch.utils.data.DataLoader(val_dataset,\n","                                         batch_size=batch_size,\n","                                         shuffle=False,\n","                                         num_workers=4,\n","                                         collate_fn=collate,\n","                                         sampler=val_samp)\n","test_loader = torch.utils.data.DataLoader(test_dataset,\n","                                         batch_size=batch_size,\n","                                         shuffle=False,\n","                                         num_workers=4,\n","                                         collate_fn=collate,\n","                                         sampler=te_samp)\n","len(train_loader), len(val_loader), len(test_loader)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"do8QGVOJEmIf","executionInfo":{"status":"ok","timestamp":1733807131252,"user_tz":360,"elapsed":1268,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}}},"outputs":[],"source":["# get/create model\n","def get_model(num_classes):\n","    # model types: fasterrcnn_resnet50_fpn,\n","    #              fasterrcnn_resnet50_fpn_v2,\n","    #              fasterrcnn_mobilenet_v3_large_fpn,\n","    #              fasterrcnn_mobilenet_v3_large_320_fpn\n","    model = fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n","\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","    return model\n","\n","model = get_model(num_classes=138)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"AWGOjtEZEmIg","executionInfo":{"status":"ok","timestamp":1733807131710,"user_tz":360,"elapsed":462,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}}},"outputs":[],"source":["# train and evaluate model\n","lr = 0.001\n","epochs = 10\n","metric = MeanAveragePrecision()\n","optimizer = optim.AdamW(model.parameters(), lr=lr)\n","smmfr = FRCNNModelManager(model=model,\n","                         metric=metric,\n","                         optimizer=optimizer,\n","                         device=device)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"r6DhEiYbEmIh","executionInfo":{"status":"error","timestamp":1733807655802,"user_tz":360,"elapsed":524097,"user":{"displayName":"Scott Schmidl","userId":"07500865660181256076"}},"collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":367},"outputId":"d3efa069-9c05-4b5d-fd0a-4754209b9861"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Training for epoch 1 Complete. Total Loss: 28542.9462\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [08:43<?, ?it/s]\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'list' object has no attribute 'values'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-be08b945a7f9>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# smaller subset of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m smmfr.train(training_data_loader=train_loader,\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mvalidation_data_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             epochs=epochs,)\n","\u001b[0;32m/content/drive/MyDrive/ColabNotebooks/gt_omscs_ml/deep_learning/Convolutionalists/FoodforDeepThought/src/model_managers/standard_model_manager.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data_loader, validation_data_loader, epochs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"]}],"source":["# import xml.etree.ElementTree as ET\n","# from PIL import Image\n","\n","# data_dir = os.path.join(\"data\", \"openimages\")\n","# train_dir = os.path.join(data_dir, \"train\") # Directory in which train dataset resides\n","# imgs = list(sorted(os.listdir(os.path.join(train_dir, \"images\"))))\n","# annotations = list(sorted(os.listdir(os.path.join(train_dir, \"annotations\"))))\n","# for i, c in enumerate(classes):\n","#     img_path = os.path.join(train_dir, \"images\", imgs[i])\n","#     ann_path = os.path.join(train_dir, \"annotations\", annotations[i])\n","\n","#     img = Image.open(img_path).convert(\"RGB\")\n","\n","#     # Parse the XML annotation file\n","#     tree = ET.parse(ann_path)\n","#     root = tree.getroot()\n","\n","#     boxes = []\n","#     labels = []\n","#     for obj in root.findall('object'):\n","#         label = obj.find('name').text.capitalize()\n","#         if \"food\" in label:\n","#             label = label.replace(\"food\", \"Food\")\n","#         print(label)\n","\n","\n","# fruits 360\n","# smm.train(training_data_loader=train_fl,\n","#           validation_data_loader=val,\n","#           epochs=epochs,\n","#           has_box=False)\n","\n","# google colab\n","# reduce batch size\n","# reduce image size\n","# smaller subset of data\n","\n","smmfr.train(training_data_loader=train_loader,\n","            validation_data_loader=val_loader,\n","            epochs=epochs,)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}