{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cpu\n"
     ]
    }
   ],
   "source": [
    "# utils\n",
    "from src.model_managers.standard_model_manager import (StandardModelManager,\n",
    "                                                       FRCNNModelManager)\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# torch\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import (fasterrcnn_resnet50_fpn_v2, \n",
    "                                         fasterrcnn_resnet50_fpn)\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "#import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import tv_tensors\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "# transfomers\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# load data\n",
    "from src.dataset_loaders.download_openimages import (OpenImagesLoader,\n",
    "                                                     ImageLoaderFRCNN)\n",
    "from src.dataset_loaders.fruits360 import Fruits360Loader\n",
    "\n",
    "# set device\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "\n",
    "print(f\"Device being used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12531, 1601, 1660)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "# fl = Fruits360Loader(random_seed=101,\n",
    "#                      batch_size=128,\n",
    "#                      perc_keep=1.0)\n",
    "# train_fl, val_fl, test_fl = fl.load_data()\n",
    "\n",
    "# oil = OpenImagesLoader(random_seed=101,\n",
    "#                        batch_size=128,\n",
    "#                        perc_keep=1.0,\n",
    "#                        num_images_per_class=500,)\n",
    "\n",
    "# oil.download_data(annotation_format='pascal')\n",
    "# oil.split_data(keep_class_dirs=False)\n",
    "#train, val, test = oil.get_datasets()\n",
    "\n",
    "\n",
    "# csb = pd.read_csv(\"data/openimages_csv_dir/class-descriptions-boxable.csv\",\n",
    "#                   header=None,\n",
    "#                   names=['LabelName',\n",
    "#                            'Label'])\n",
    "# trabb = pd.read_csv(\"data/openimages_csv_dir/train-annotations-bbox.csv\",)\n",
    "# vabb = pd.read_csv(\"data/openimages_csv_dir/validation-annotations-bbox.csv\",)\n",
    "# teabb = pd.read_csv(\"data/openimages_csv_dir/test-annotations-bbox.csv\",)\n",
    "\n",
    "# food_cats = [\"Hot dog\", \"French fries\", \"Waffle\", \"Pancake\", \"Burrito\", \"Pretzel\",\n",
    "#             \"Popcorn\", \"Cookie\", \"Muffin\", \"Ice cream\", \"Cake\", \"Candy\",\n",
    "#             \"Guacamole\", \"Apple\", \"Grape\", \"Common fig\", \"Pear\",\n",
    "#             \"Strawberry\", \"Tomato\", \"Lemon\", \"Banana\", \"Orange\", \"Peach\", \"Mango\",\n",
    "#             \"Pineapple\", \"Grapefruit\", \"Pomegranate\", \"Watermelon\", \"Cantaloupe\",\n",
    "#             \"Egg (Food)\", \"Bagel\", \"Bread\", \"Doughnut\", \"Croissant\",\n",
    "#             \"Tart\", \"Mushroom\", \"Pasta\", \"Pizza\", \"Squid\",\n",
    "#             \"Oyster\", \"Lobster\", \"Shrimp\", \"Crab\", \"Taco\", \"Cooking spray\",\n",
    "#             \"Cucumber\", \"Radish\", \"Artichoke\", \"Potato\", \"Garden Asparagus\",\n",
    "#             \"Pumpkin\", \"Zucchini\", \"Cabbage\", \"Carrot\", \"Salad\",\n",
    "#             \"Broccoli\", \"Bell pepper\", \"Winter melon\", \"Honeycomb\",\n",
    "#             \"Hamburger\", \"Submarine sandwich\", \"Cheese\", \"Milk\", \"Sushi\"]\n",
    "\n",
    "# csb = csb[csb['Label'].isin(food_cats)]\n",
    "# csb\n",
    "\n",
    "# print(len(trabb))\n",
    "# trabb = trabb[trabb['LabelName'].isin(csb[\"LabelName\"])]\n",
    "# print(len(trabb))\n",
    "# trabb_csb = pd.merge(csb, trabb, on='LabelName', how='inner')\n",
    "# print(len(trabb_csb))\n",
    "# trabb_csb\n",
    "\n",
    "# print(len(vabb))\n",
    "# vabb = vabb[vabb['LabelName'].isin(csb[\"LabelName\"])]\n",
    "# print(len(vabb))\n",
    "# vabb_csb = pd.merge(csb, vabb, on='LabelName', how='inner')\n",
    "# print(len(vabb_csb))\n",
    "# vabb_csb\n",
    "\n",
    "# print(len(teabb))\n",
    "# teabb = teabb[teabb['LabelName'].isin(csb[\"LabelName\"])]\n",
    "# print(len(teabb))\n",
    "# teabb_csb = pd.merge(csb, teabb, on='LabelName', how='inner')\n",
    "# print(len(teabb_csb))\n",
    "# teabb_csb\n",
    "\n",
    "# train_target = [{\"label\": torch.Tensor(row[\"Label\"]),\n",
    "#                  \"boxes\": torch.tensor([row[\"XMin\"], row[\"XMax\"], row[\"YMin\"], row[\"YMax\"]])}\n",
    "#                 for _, row in trabb_csb.iterrows()]\n",
    "# train_target\n",
    "\n",
    "def get_transform(train):\n",
    "    transf = []\n",
    "    transf.append(v2.Resize((100)))\n",
    "    transf.append(v2.ToTensor())\n",
    "    if train:\n",
    "        transf.append(v2.Normalize(mean=[0.485,\n",
    "                                                 0.456,\n",
    "                                                 0.406],\n",
    "                                           std=[0.229,\n",
    "                                                0.224,\n",
    "                                                0.225]))\n",
    "\n",
    "    return v2.Compose(transf)\n",
    "\n",
    "ttform = get_transform(train=True)\n",
    "vtform = get_transform(train=False)\n",
    "    \n",
    "loader = OpenImagesLoader(random_seed=101,\n",
    "                         batch_size=32,\n",
    "                         perc_keep=1.0,\n",
    "                         num_images_per_class=500,)\n",
    "opim_dir = loader.data_dir\n",
    "seed = loader.random_seed\n",
    "batch_size = loader.batch_size\n",
    "per_keep = loader.perc_keep\n",
    "im_per_class = loader.num_images_per_class\n",
    "\n",
    "ann_form = loader.annotation_format\n",
    "classes = loader.classes\n",
    "class2index = loader.class_2_index\n",
    "train_direct = loader.train_dir\n",
    "val_direct = loader.val_dir\n",
    "test_direct = loader.test_dir\n",
    "\n",
    "train_dataset = ImageLoaderFRCNN(root=train_direct,\n",
    "                                 classes=classes,\n",
    "                                 tforms=ttform)\n",
    "val_dataset = ImageLoaderFRCNN(root=val_direct,\n",
    "                               classes=classes,\n",
    "                               tforms=vtform)\n",
    "test_dataset = ImageLoaderFRCNN(root=test_direct,\n",
    "                               classes=classes,)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 4, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx = list(range(1000))  # This will include indices 0 to 7500\n",
    "val_idx = list(range(100))  # This will include indices 0 to 1000\n",
    "test_idx = list(range(100))  # This will include indices 0 to 1000\n",
    "tr_samp = SubsetRandomSampler(train_idx)\n",
    "val_samp = SubsetRandomSampler(val_idx)\n",
    "te_samp = SubsetRandomSampler(test_idx)\n",
    "\n",
    "def collate(data):\n",
    "    return tuple(zip(*data))\n",
    "\n",
    "# without sampling lengths were train_loader: 98, val_loader: 13, test_loader: 13\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate,\n",
    "                                           sampler=tr_samp)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=collate,\n",
    "                                         sampler=val_samp)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=collate,\n",
    "                                         sampler=te_samp)\n",
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get/create model\n",
    "def get_model(num_classes):\n",
    "    # model types: fasterrcnn_resnet50_fpn,\n",
    "    #              fasterrcnn_resnet50_fpn_v2,\n",
    "    #              fasterrcnn_mobilenet_v3_large_fpn,\n",
    "    #              fasterrcnn_mobilenet_v3_large_320_fpn\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "        \n",
    "model = get_model(num_classes=138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate model\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "metric = MeanAveragePrecision()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "smmfr = FRCNNModelManager(model=model, \n",
    "                         metric=metric, \n",
    "                         optimizer=optimizer,\n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import xml.etree.ElementTree as ET\n",
    "# from PIL import Image\n",
    "\n",
    "# data_dir = os.path.join(\"data\", \"openimages\") \n",
    "# train_dir = os.path.join(data_dir, \"train\") # Directory in which train dataset resides\n",
    "# imgs = list(sorted(os.listdir(os.path.join(train_dir, \"images\"))))\n",
    "# annotations = list(sorted(os.listdir(os.path.join(train_dir, \"annotations\"))))\n",
    "# for i, c in enumerate(classes):\n",
    "#     img_path = os.path.join(train_dir, \"images\", imgs[i])\n",
    "#     ann_path = os.path.join(train_dir, \"annotations\", annotations[i])\n",
    "            \n",
    "#     img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "#     # Parse the XML annotation file\n",
    "#     tree = ET.parse(ann_path)\n",
    "#     root = tree.getroot()\n",
    "\n",
    "#     boxes = []\n",
    "#     labels = []\n",
    "#     for obj in root.findall('object'):\n",
    "#         label = obj.find('name').text.capitalize()\n",
    "#         if \"food\" in label:\n",
    "#             label = label.replace(\"food\", \"Food\")\n",
    "#         print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in epoch loop: 1\n",
      "in training loop: 1\n",
      "running model: 1\n"
     ]
    }
   ],
   "source": [
    "# fruits 360\n",
    "# smm.train(training_data_loader=train_fl,\n",
    "#           validation_data_loader=val,\n",
    "#           epochs=epochs,\n",
    "#           has_box=False)\n",
    "\n",
    "# google colab\n",
    "# reduce batch size\n",
    "# reduce image size\n",
    "# smaller subset of data\n",
    "\n",
    "smmfr.train(training_data_loader=train_loader,\n",
    "            validation_data_loader=val_loader,\n",
    "            epochs=epochs,\n",
    "            has_box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convolutionalists",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
